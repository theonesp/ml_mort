---
title: "03_train_test_df_creation"
author: "Miguel Armengol"
date: "2/20/2019"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading libraries

```{r message=FALSE, warning=FALSE}
library(dplyr)
library(caret)
```

# Creating de-identified id

```{r}

abp_mean_all_data['id']<- seq.int(nrow(abp_mean_all_data))
abp_mean_all_data_deid<-abp_mean_all_data
abp_mean_all_data_deid$Case_Name<-NULL
```

# Spliting de-identified data into testing and training, balanced version.

We want the data to be sampled randomly but always the same way and we want to be sure that train and test must be balanced.

```{r}
## set the seed to make our partition reproducible
set.seed(123)
# createDataPartition: "the random sampling is done within the levels of y when y is a factor in an attempt to balance the class distributions within the splits."
## 75% of the sample size
train_idx <- createDataPartition(as.factor(abp_mean_all_data_deid$Death), times = 1, p = 0.75, list=F)

train <- abp_mean_all_data_deid[train_idx, ]
test <- abp_mean_all_data_deid[-train_idx, ]

round(prop.table(table(train$Death)),2)
round(prop.table(table(test$Death)),2)
```

## Exporting datasets

```{r}
write.csv(train,'../data/train.csv',row.names = F)
write.csv(test,'../data/test.csv',row.names = F)
```


## Checking proportion of outcomes

```{r}
round(prop.table(table(train$Any_MAE)),2)
```


# Spliting de-identified data into testing and training, unbalanced version.

The original dataset has a total of 5020 rows.

We are going to adjust how the 1s of the outcome (506) are divided across training and test sets in the proportion of 30%, 70%.
The overall proportion of patients in training and test dataset is still 75%-25% respectively. 

ub in the following datasets stands for unbalanced.

```{r}
## CREATING THE TRAIN UNBALANCED DATASET

## set the seed to make our partition reproducible
set.seed(123)

# select random 30 % rows of the dataframe where Any_MAE ==1
train_ub<-abp_mean_all_data_deid%>%
filter(Any_MAE==1) %>%
sample_n(152) # 30% of 506 rows with Any_MAE = 1

#152 represents 4% of total number of rows (3765) in the training dataset which is 75% of the total dataset, so we still need 96 % of rows (3613) where Any_MAE == 0

train_ub<-rbind(train_ub,
      abp_mean_all_data_deid%>%
      filter(Any_MAE==0) %>%
      sample_n(3613)
      )

#creating 'not in' function
'%!in%' <- function(x,y)!('%in%'(x,y))

## CREATING THE TEST UNBALANCED DATASET

# select random 70 % rows of the dataframe where Any_MAE ==1 and that have not been included in the training dataset
test_ub<-abp_mean_all_data_deid%>%
filter(Any_MAE==1 & id %!in% train_ub$id) %>%
sample_n(354) # 70% of 506 rows with Any_MAE = 1

#354 represents 28% of total number of rows (1255) in the test dataset which is 25% of the total dataset, so we still need 72 % of rows (3613) where Any_MAE == 0 and that have not been included in the training dataset

test_ub<-rbind(test_ub,
      abp_mean_all_data_deid%>%
      filter(Any_MAE==0 & id %!in% train_ub$id) %>%
      sample_n(901)
      )
```

## Exporting datasets

```{r}
write.csv(train_ub,'train_ub.csv',row.names = F)
write.csv(test_ub,'test_ub.csv',row.names = F)
```









